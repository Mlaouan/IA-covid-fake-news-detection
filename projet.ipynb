{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mlaouan/IA-covid-fake-news-detection/blob/main/projet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "768d16c6",
      "metadata": {
        "id": "768d16c6"
      },
      "source": [
        "# phase de préparation des données"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06cad21f",
      "metadata": {
        "id": "06cad21f"
      },
      "source": [
        "## 1.1 nettoyage"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "henQruvBMuUs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b294605b-39ae-434b-90cd-8f37636900e1"
      },
      "id": "henQruvBMuUs",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c1765f3",
      "metadata": {
        "id": "3c1765f3",
        "outputId": "846ff85e-96cb-4927-c575-61654be4243f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        id                                              tweet label\n",
            "0        1  The CDC currently reports 99031 deaths. In gen...  real\n",
            "1        2  States reported 1121 deaths a small rise from ...  real\n",
            "2        3  Politically Correct Woman (Almost) Uses Pandem...  fake\n",
            "3        4  #IndiaFightsCorona: We have 1524 #COVID testin...  real\n",
            "4        5  Populous states can generate large case counts...  real\n",
            "...    ...                                                ...   ...\n",
            "6415  6416  A tiger tested positive for COVID-19 please st...  fake\n",
            "6416  6417  ???Autopsies prove that COVID-19 is??� a blood...  fake\n",
            "6417  6418  _A post claims a COVID-19 vaccine has already ...  fake\n",
            "6418  6419  Aamir Khan Donate 250 Cr. In PM Relief Cares Fund  fake\n",
            "6419  6420  It has been 93 days since the last case of COV...  real\n",
            "\n",
            "[6420 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "#chargement des données\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import nltk\n",
        "import re\n",
        "import string\n",
        "df=pd.read_excel('drive/My Drive/Colab Notebooks/Data-FakeRealCOVID.xlsx')\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed5b5fe9",
      "metadata": {
        "id": "ed5b5fe9",
        "outputId": "553ff8d1-e287-4d62-b1ab-3f86b78cf99f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       The CDC currently reports 99031 deaths. In gen...\n",
              "1       States reported 1121 deaths a small rise from ...\n",
              "2       Politically Correct Woman (Almost) Uses Pandem...\n",
              "3       #IndiaFightsCorona: We have 1524 #COVID testin...\n",
              "4       Populous states can generate large case counts...\n",
              "                              ...                        \n",
              "6415    A tiger tested positive for COVID-19 please st...\n",
              "6416    ???Autopsies prove that COVID-19 is??� a blood...\n",
              "6417    _A post claims a COVID-19 vaccine has already ...\n",
              "6418    Aamir Khan Donate 250 Cr. In PM Relief Cares Fund\n",
              "6419    It has been 93 days since the last case of COV...\n",
              "Name: tweet, Length: 6420, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "#on visualise les tweets\n",
        "df.tweet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28380acb",
      "metadata": {
        "id": "28380acb",
        "outputId": "390cf8e8-209b-42ef-c35b-1ac1fddde1db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       The CDC currently reports 99031 deaths. In gen...\n",
              "1       States reported 1121 deaths a small rise from ...\n",
              "2       Politically Correct Woman (Almost) Uses Pandem...\n",
              "3       #IndiaFightsCorona: We have 1524 #COVID testin...\n",
              "4       Populous states can generate large case counts...\n",
              "                              ...                        \n",
              "6415    A tiger tested positive for COVID-19 please st...\n",
              "6416    ???Autopsies prove that COVID-19 is??� a blood...\n",
              "6417    _A post claims a COVID-19 vaccine has already ...\n",
              "6418    Aamir Khan Donate 250 Cr. In PM Relief Cares Fund\n",
              "6419    It has been 93 days since the last case of COV...\n",
              "Name: clean_tweet, Length: 6420, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "#on supprime les liens\n",
        "df['clean_tweet'] = df[\"tweet\"].apply(lambda s: ' '.join(re.sub(\"https?:\\/\\/.*[\\r\\n]*\", \"\", s).split()))\n",
        "df['clean_tweet']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72f77275",
      "metadata": {
        "id": "72f77275",
        "outputId": "75ba1e56-fc3a-471d-8a05-416835fc5d63",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       The CDC currently reports 99031 deaths. In gen...\n",
              "1       States reported 1121 deaths a small rise from ...\n",
              "2       Politically Correct Woman (Almost) Uses Pandem...\n",
              "3       #IndiaFightsCorona: We have 1524 #COVID testin...\n",
              "4       Populous states can generate large case counts...\n",
              "                              ...                        \n",
              "6415    A tiger tested positive for COVID-19 please st...\n",
              "6416    ???Autopsies prove that COVID-19 is??� a blood...\n",
              "6417    _A post claims a COVID-19 vaccine has already ...\n",
              "6418    Aamir Khan Donate 250 Cr. In PM Relief Cares Fund\n",
              "6419    It has been 93 days since the last case of COV...\n",
              "Name: clean_tweet, Length: 6420, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "#retire les mentions, \n",
        "df['clean_tweet'] = df['clean_tweet'].apply(lambda s: ' '.join(re.sub(\"@\\S+\", \"\",s).split()))\n",
        "df['clean_tweet']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8999bb1d",
      "metadata": {
        "id": "8999bb1d",
        "outputId": "0fdd7048-6410-451c-c62e-8c732fc4b23c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       The CDC currently reports 99031 deaths. In gen...\n",
              "1       States reported 1121 deaths a small rise from ...\n",
              "2       Politically Correct Woman (Almost) Uses Pandem...\n",
              "3       We have 1524 testing laboratories in India and...\n",
              "4       Populous states can generate large case counts...\n",
              "                              ...                        \n",
              "6415    A tiger tested positive for COVID-19 please st...\n",
              "6416    ???Autopsies prove that COVID-19 is??� a blood...\n",
              "6417    _A post claims a COVID-19 vaccine has already ...\n",
              "6418    Aamir Khan Donate 250 Cr. In PM Relief Cares Fund\n",
              "6419    It has been 93 days since the last case of COV...\n",
              "Name: clean_tweet, Length: 6420, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "#hashtags #####voir avec re.sub(\"#\", \"\", s)\n",
        "df['clean_tweet'] = df['clean_tweet'].apply(lambda s: ' '.join(re.sub(\"#\\S+\", \"\",s).split()))\n",
        "df['clean_tweet']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAr9hm9HXZc5",
        "outputId": "2e9f46f5-7b37-4ffa-bab8-6518e2ed500b"
      },
      "id": "EAr9hm9HXZc5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5dd677b3",
      "metadata": {
        "id": "5dd677b3",
        "outputId": "c7891447-13a5-4d76-e3ea-ce66adf6a8b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'his', 'too', 'ourselves', \"doesn't\", 'are', 'we', 'now', 'them', 'does', 'down', 'been', 'having', 'from', \"haven't\", 'weren', 'hers', 'i', 'don', 'am', 'were', 'under', 'just', 's', 'for', 'no', 'herself', \"couldn't\", 'as', 'himself', 'an', 'into', 'before', 'theirs', 'any', \"hadn't\", \"that'll\", 'on', 'about', \"shan't\", \"mustn't\", 'have', 'y', 'themselves', \"shouldn't\", 'o', 'itself', 'between', \"mightn't\", 'him', \"it's\", 'has', 'couldn', 'out', 'because', 'to', 'further', 've', 'how', 'nor', \"wouldn't\", \"aren't\", 'she', 'shan', 'until', 'mightn', 'our', 'where', 'own', \"should've\", 'below', \"weren't\", \"you've\", 'what', 'in', 'than', 'of', \"didn't\", 'doesn', 'over', \"won't\", 'not', 'they', 'whom', \"isn't\", 'this', 'off', 'myself', 'above', 'your', \"you'd\", 'same', 'doing', \"wasn't\", \"hasn't\", 'had', 'wasn', 'won', \"you're\", 'needn', 'aren', 'the', 'up', 'ain', 'me', 'her', 'be', 'do', 'through', 'by', 'all', 'was', 'very', 'that', 'yourself', 'it', 'd', 'such', 'didn', 'hadn', 'few', \"needn't\", 'is', 'with', 'more', 'once', 'did', 'if', 'll', 'ma', 'while', 'or', 'who', 'will', 'a', 'he', 're', 'most', 'both', 'why', \"she's\", 'being', 'against', 'wouldn', 'haven', 't', 'at', 'yours', 'those', 'mustn', 'their', 'yourselves', 'and', 'during', 'after', 'which', 'there', 'when', 'only', 'so', \"you'll\", 'some', 'these', 'then', 'hasn', 'each', 'ours', 'here', 'its', 'should', 'shouldn', \"don't\", 'm', 'other', 'my', 'isn', 'but', 'you', 'can', 'again'}\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import stopwords\n",
        "stops = set(stopwords.words('english'))\n",
        "print(stops)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7cefc467",
      "metadata": {
        "id": "7cefc467",
        "outputId": "233822c3-6c09-41fe-ff6d-aaac6a0be5cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       cdc currently reports 99031 deaths. general di...\n",
              "1       states reported 1121 deaths small rise last tu...\n",
              "2       politically correct woman (almost) uses pandem...\n",
              "3       1524 testing laboratories india 25th august 20...\n",
              "4       populous states generate large case counts loo...\n",
              "                              ...                        \n",
              "6415    tiger tested positive covid-19 please stay awa...\n",
              "6416    ???autopsies prove covid-19 is??� blood clot, ...\n",
              "6417    _a post claims covid-19 vaccine already develo...\n",
              "6418       aamir khan donate 250 cr. pm relief cares fund\n",
              "6419    93 days since last case covid-19 acquired loca...\n",
              "Name: clean_tweet, Length: 6420, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "#stopwords et minuscule\n",
        "#definition de la fonction rem_en qui supprime un mot si c'est un stopwords\n",
        "def rem_en(input_txt):\n",
        "    words = input_txt.lower()\n",
        "    words=\" \".join([word for word in words.split() if word not in stops])\n",
        "    return words\n",
        "df['clean_tweet'] = df['clean_tweet'].apply(lambda s: rem_en(s))\n",
        "df['clean_tweet']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "446d8815",
      "metadata": {
        "id": "446d8815",
        "outputId": "2b0e6799-3022-4a91-b3d3-d190bdd760a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       cdc currently reports 99031 deaths. general di...\n",
              "1       states reported 1121 deaths small rise last tu...\n",
              "2       politically correct woman (almost) uses pandem...\n",
              "3       1524 testing laboratories india 25th august 20...\n",
              "4       populous states generate large case counts loo...\n",
              "                              ...                        \n",
              "6415    tiger tested positive covid-19 please stay awa...\n",
              "6416    ???autopsies prove covid-19 is?? blood clot, p...\n",
              "6417    _a post claims covid-19 vaccine already develo...\n",
              "6418       aamir khan donate 250 cr. pm relief cares fund\n",
              "6419    93 days since last case covid-19 acquired loca...\n",
              "Name: clean_tweet, Length: 6420, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "#emoji\n",
        "def deEmojify(inputString):\n",
        "    return inputString.encode('ascii', 'ignore').decode('ascii')\n",
        "df['clean_tweet'] = df['clean_tweet'].apply(lambda s: deEmojify(s))\n",
        "df['clean_tweet']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cc3dca5",
      "metadata": {
        "id": "1cc3dca5",
        "outputId": "21617027-18b5-494e-f0ac-54f6ba2528b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       cdc currently reports 99031 deaths  general di...\n",
              "1       states reported 1121 deaths small rise last tu...\n",
              "2       politically correct woman  almost  uses pandem...\n",
              "3       1524 testing laboratories india 25th august 20...\n",
              "4       populous states generate large case counts loo...\n",
              "                              ...                        \n",
              "6415    tiger tested positive covid 19 please stay awa...\n",
              "6416       autopsies prove covid 19 is   blood clot  p...\n",
              "6417     a post claims covid 19 vaccine already develo...\n",
              "6418       aamir khan donate 250 cr  pm relief cares fund\n",
              "6419    93 days since last case covid 19 acquired loca...\n",
              "Name: clean_tweet, Length: 6420, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "#ponctuations\n",
        "punct = set(string.punctuation)\n",
        "punctuation = re.compile(r'[-_.?!,%\":;()|&$]')\n",
        "def ponct(input_txt):\n",
        "    words=\"\".join([punctuation.sub(\" \", ch) for ch in input_txt])\n",
        "    return words\n",
        "df['clean_tweet'] = df['clean_tweet'].apply(lambda s: ponct(s))\n",
        "df['clean_tweet']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1244c41f",
      "metadata": {
        "id": "1244c41f",
        "outputId": "b37e92a5-9595-41ea-e52d-dfd360b95cdf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{',', '$', ']', '!', '<', '?', '>', '&', '*', '|', '`', \"'\", '+', '\\\\', ';', '_', '}', '~', '/', '-', '\"', '[', '%', ':', ')', '=', '#', '{', '.', '@', '^', '('}\n"
          ]
        }
      ],
      "source": [
        "print(punct)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b149c0ab",
      "metadata": {
        "id": "b149c0ab",
        "outputId": "336dea94-54d2-466c-820e-dff34d951408",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       cdc currently reports deaths general discrepan...\n",
              "1       states reported deaths small rise last tuesday...\n",
              "2       politically correct woman almost uses pandemic...\n",
              "3         testing laboratories india august tests done dg\n",
              "4       populous states generate large case counts loo...\n",
              "                              ...                        \n",
              "6415    tiger tested positive covid please stay away p...\n",
              "6416    autopsies prove covid is blood clot pneumonia ...\n",
              "6417    a post claims covid vaccine already developed ...\n",
              "6418            aamir khan donate cr pm relief cares fund\n",
              "6419    days since last case covid acquired locally un...\n",
              "Name: clean_tweet, Length: 6420, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "#nombres\n",
        "df['clean_tweet'] = df['clean_tweet'].apply(lambda s: ' '.join(re.sub(\"[0-9]\\S+\", \"\",s).split()))\n",
        "df['clean_tweet']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05f09595",
      "metadata": {
        "id": "05f09595",
        "outputId": "5fefb4f5-a37e-4263-9df3-f6d437b7e1b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'mha issues guidelines metro rail services resume september public gatherings allowed ceiling persons september open air theaters permitted open september'"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "df['clean_tweet'][5538]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebcf4f0b",
      "metadata": {
        "id": "ebcf4f0b",
        "outputId": "653d39cd-298b-4f3d-df55-7fc64088b8d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       cdc currently report death general discrepancy...\n",
              "1       state reported death small rise last tuesday s...\n",
              "2       politically correct woman almost us pandemic e...\n",
              "3            testing laboratory india august test done dg\n",
              "4       populous state generate large case count look ...\n",
              "                              ...                        \n",
              "6415    tiger tested positive covid please stay away p...\n",
              "6416    autopsy prove covid is blood clot pneumonia an...\n",
              "6417    a post claim covid vaccine already developed c...\n",
              "6418             aamir khan donate cr pm relief care fund\n",
              "6419    day since last case covid acquired locally unk...\n",
              "Name: clean_tweet, Length: 6420, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "#lemmalisation\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "from nltk.tokenize import word_tokenize\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "def lemm(input_txt):\n",
        "    words = nltk.word_tokenize(input_txt)\n",
        "    words = ' '.join([lemmatizer.lemmatize(word) for word in words])\n",
        "    return words\n",
        "df['clean_tweet'] = df['clean_tweet'].apply(lambda s: lemm(s))\n",
        "df['clean_tweet']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f7e7c45",
      "metadata": {
        "id": "7f7e7c45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e223421-4d73-4699-9d56-ef3623e70560"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       cdc current report death general discrep death...\n",
              "1       state report death small rise last tuesday sou...\n",
              "2       polit correct woman almost us pandem excus reu...\n",
              "3               test laboratori india august test done dg\n",
              "4       popul state generat larg case count look new c...\n",
              "                              ...                        \n",
              "6415      tiger test posit covid pleas stay away pet bird\n",
              "6416    autopsi prove covid is blood clot pneumonia an...\n",
              "6417    a post claim covid vaccin alreadi develop caus...\n",
              "6418              aamir khan donat cr pm relief care fund\n",
              "6419    day sinc last case covid acquir local unknown ...\n",
              "Name: clean_tweet, Length: 6420, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "#stemm\n",
        "from nltk.stem import SnowballStemmer\n",
        "snow = SnowballStemmer('english')\n",
        "def stemm(input_txt):\n",
        "    words = nltk.word_tokenize(input_txt)\n",
        "    words = ' '.join([snow.stem(word) for word in words])\n",
        "    return words\n",
        "df['clean_tweet'] = df['clean_tweet'].apply(lambda s: stemm(s))\n",
        "df['clean_tweet']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95943088",
      "metadata": {
        "id": "95943088",
        "outputId": "2acc9e6d-7e2e-4c1a-9dbf-8e04db828f42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       cdc current report death general discrep death...\n",
              "1       state report death small rise last tuesday sou...\n",
              "2       polit correct woman almost us pandem excus reu...\n",
              "3               test laboratori india august test done dg\n",
              "4       popul state generat larg case count look new c...\n",
              "                              ...                        \n",
              "6415      tiger test posit covid pleas stay away pet bird\n",
              "6416    autopsi prove covid is blood clot pneumonia an...\n",
              "6417    a post claim covid vaccin alreadi develop caus...\n",
              "6418              aamir khan donat cr pm relief care fund\n",
              "6419    day sinc last case covid acquir local unknown ...\n",
              "Name: clean_tweet, Length: 6420, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "#replace les derivées de corona en covid\n",
        "df['clean_tweet'] = df['clean_tweet'].apply(lambda s: ' '.join(re.sub(\"corona\\S+\", \"covid\",s).split()))\n",
        "#df.tweet = df[\"tweet\"].apply(lambda s: ' '.join(re.sub(\"coronaviru\", \"covid\",s).split()))\n",
        "df['clean_tweet']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## mettre real fake dans 0 1\n",
        "df['redif_label'] = df['label']\n",
        "df['redif_label']=df['redif_label'].replace('real', 1)\n",
        "df['redif_label']=df['redif_label'].replace('fake', 0)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "YNM3JzZJW486",
        "outputId": "39e31ce5-7dd7-4060-a842-9c7098e5be1c"
      },
      "id": "YNM3JzZJW486",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c57f8637-ed28-4f29-8a1c-44f756173d98\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "      <th>clean_tweet</th>\n",
              "      <th>redif_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>The CDC currently reports 99031 deaths. In gen...</td>\n",
              "      <td>real</td>\n",
              "      <td>cdc current report death general discrep death...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>States reported 1121 deaths a small rise from ...</td>\n",
              "      <td>real</td>\n",
              "      <td>state report death small rise last tuesday sou...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Politically Correct Woman (Almost) Uses Pandem...</td>\n",
              "      <td>fake</td>\n",
              "      <td>polit correct woman almost us pandem excus reu...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>#IndiaFightsCorona: We have 1524 #COVID testin...</td>\n",
              "      <td>real</td>\n",
              "      <td>test laboratori india august test done dg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Populous states can generate large case counts...</td>\n",
              "      <td>real</td>\n",
              "      <td>popul state generat larg case count look new c...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c57f8637-ed28-4f29-8a1c-44f756173d98')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c57f8637-ed28-4f29-8a1c-44f756173d98 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c57f8637-ed28-4f29-8a1c-44f756173d98');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   id  ... redif_label\n",
              "0   1  ...           1\n",
              "1   2  ...           1\n",
              "2   3  ...           0\n",
              "3   4  ...           1\n",
              "4   5  ...           1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#for i in range(6420):\n",
        "#  for word in df.clean_tweet[i]:\n",
        "#    if len(word)<3:\n",
        "#      df.clean_tweet[i].remove(word)"
      ],
      "metadata": {
        "id": "E6THNkwkuiIX"
      },
      "id": "E6THNkwkuiIX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "e5a77c50",
      "metadata": {
        "id": "e5a77c50"
      },
      "source": [
        "## 1.2 bags of words avec TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1. PHASE DE VECTORISATION\n",
        "\n",
        "# create Word2vec model\n",
        "#here words_f should be a list containing words from each document. say 1st row of the list is words from the 1st document/sentence\n",
        "#length of words_f is number of documents/sentences in your dataset\n",
        "df['clean_tweet_tok']=[nltk.word_tokenize(i) for i in df['clean_tweet']] #convert preprocessed sentence to tokenized sentence\n",
        "#model = Word2Vec(df['clean_tweet_tok'],min_count=1)  #min_count=1 means word should be present at least across all documents,\n",
        "#if min_count=2 means if the word is present less than 2 times across all the documents then we shouldn't consider it\n",
        "\n",
        "\n",
        "#w2v = dict(zip(model.wv.index2word, model.wv.syn0))  #combination of word and its vector\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "Ytd8IusFsZfT",
        "outputId": "f525239b-6b8a-4dfa-cda3-fbbf1e48a57a"
      },
      "id": "Ytd8IusFsZfT",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-78dc8b9f-ea21-4f67-8cc6-76357948b156\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "      <th>clean_tweet</th>\n",
              "      <th>redif_label</th>\n",
              "      <th>clean_tweet_tok</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>The CDC currently reports 99031 deaths. In gen...</td>\n",
              "      <td>real</td>\n",
              "      <td>cdc current report death general discrep death...</td>\n",
              "      <td>1</td>\n",
              "      <td>[cdc, current, report, death, general, discrep...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>States reported 1121 deaths a small rise from ...</td>\n",
              "      <td>real</td>\n",
              "      <td>state report death small rise last tuesday sou...</td>\n",
              "      <td>1</td>\n",
              "      <td>[state, report, death, small, rise, last, tues...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Politically Correct Woman (Almost) Uses Pandem...</td>\n",
              "      <td>fake</td>\n",
              "      <td>polit correct woman almost us pandem excus reu...</td>\n",
              "      <td>0</td>\n",
              "      <td>[polit, correct, woman, almost, us, pandem, ex...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>#IndiaFightsCorona: We have 1524 #COVID testin...</td>\n",
              "      <td>real</td>\n",
              "      <td>test laboratori india august test done dg</td>\n",
              "      <td>1</td>\n",
              "      <td>[test, laboratori, india, august, test, done, dg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Populous states can generate large case counts...</td>\n",
              "      <td>real</td>\n",
              "      <td>popul state generat larg case count look new c...</td>\n",
              "      <td>1</td>\n",
              "      <td>[popul, state, generat, larg, case, count, loo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6415</th>\n",
              "      <td>6416</td>\n",
              "      <td>A tiger tested positive for COVID-19 please st...</td>\n",
              "      <td>fake</td>\n",
              "      <td>tiger test posit covid pleas stay away pet bird</td>\n",
              "      <td>0</td>\n",
              "      <td>[tiger, test, posit, covid, pleas, stay, away,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6416</th>\n",
              "      <td>6417</td>\n",
              "      <td>???Autopsies prove that COVID-19 is??� a blood...</td>\n",
              "      <td>fake</td>\n",
              "      <td>autopsi prove covid is blood clot pneumonia an...</td>\n",
              "      <td>0</td>\n",
              "      <td>[autopsi, prove, covid, is, blood, clot, pneum...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6417</th>\n",
              "      <td>6418</td>\n",
              "      <td>_A post claims a COVID-19 vaccine has already ...</td>\n",
              "      <td>fake</td>\n",
              "      <td>a post claim covid vaccin alreadi develop caus...</td>\n",
              "      <td>0</td>\n",
              "      <td>[a, post, claim, covid, vaccin, alreadi, devel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6418</th>\n",
              "      <td>6419</td>\n",
              "      <td>Aamir Khan Donate 250 Cr. In PM Relief Cares Fund</td>\n",
              "      <td>fake</td>\n",
              "      <td>aamir khan donat cr pm relief care fund</td>\n",
              "      <td>0</td>\n",
              "      <td>[aamir, khan, donat, cr, pm, relief, care, fund]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6419</th>\n",
              "      <td>6420</td>\n",
              "      <td>It has been 93 days since the last case of COV...</td>\n",
              "      <td>real</td>\n",
              "      <td>day sinc last case covid acquir local unknown ...</td>\n",
              "      <td>1</td>\n",
              "      <td>[day, sinc, last, case, covid, acquir, local, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6420 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-78dc8b9f-ea21-4f67-8cc6-76357948b156')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-78dc8b9f-ea21-4f67-8cc6-76357948b156 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-78dc8b9f-ea21-4f67-8cc6-76357948b156');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        id  ...                                    clean_tweet_tok\n",
              "0        1  ...  [cdc, current, report, death, general, discrep...\n",
              "1        2  ...  [state, report, death, small, rise, last, tues...\n",
              "2        3  ...  [polit, correct, woman, almost, us, pandem, ex...\n",
              "3        4  ...  [test, laboratori, india, august, test, done, dg]\n",
              "4        5  ...  [popul, state, generat, larg, case, count, loo...\n",
              "...    ...  ...                                                ...\n",
              "6415  6416  ...  [tiger, test, posit, covid, pleas, stay, away,...\n",
              "6416  6417  ...  [autopsi, prove, covid, is, blood, clot, pneum...\n",
              "6417  6418  ...  [a, post, claim, covid, vaccin, alreadi, devel...\n",
              "6418  6419  ...   [aamir, khan, donat, cr, pm, relief, care, fund]\n",
              "6419  6420  ...  [day, sinc, last, case, covid, acquir, local, ...\n",
              "\n",
              "[6420 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7df86ba",
      "metadata": {
        "id": "d7df86ba"
      },
      "source": [
        "## 1.3 séparation des données d'apprentissage, test et validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af9099f1",
      "metadata": {
        "id": "af9099f1"
      },
      "outputs": [],
      "source": [
        "#données apprentissage et test\n",
        "from sklearn.model_selection import train_test_split\n",
        "#df_training, df_validation=train_test_split(df_count_vect, train_size=9/10)\n",
        "#df_train, df_test=train_test_split(df_training, train_size=2/3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(df[\"clean_tweet\"],\n",
        "                                                  df[\"redif_label\"],\n",
        "                                                  test_size=0.2,\n",
        "                                                  shuffle=True)"
      ],
      "metadata": {
        "id": "GRkdphsXY7UF"
      },
      "id": "GRkdphsXY7UF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TF-IDF\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# Convert x_train to vector since model can only run on numbers and not words- Fit and transform\n",
        "tfidf_vectorizer = TfidfVectorizer(use_idf=True)\n",
        "X_train_vectors_tfidf = tfidf_vectorizer.fit_transform(X_train) #tfidf runs on non-tokenized sentences unlike word2vec\n",
        "#count_tokens=X_train_vectors_fit.get_feature_names_out()\n",
        "#X_train_vectors_tfidf=X_train_vectors_fit.transform(X_train)\n",
        "# Only transform x_test (not fit and transform)\n",
        "X_val_vectors_tfidf = tfidf_vectorizer.transform(X_val) #Don't fit() your TfidfVectorizer to your test data: it will \n",
        "#change the word-indexes & weights to match test data. Rather, fit on the training data, then use the same train-data-\n",
        "#fit model on the test data, to reflect the fact you're analyzing the test data only based on what was learned without \n",
        "#it, and the have compatible"
      ],
      "metadata": {
        "id": "eHHgyTF6svG1"
      },
      "id": "eHHgyTF6svG1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shape=X_train_vectors_tfidf.shape[1]"
      ],
      "metadata": {
        "id": "Smzo-ZvJsxsH"
      },
      "id": "Smzo-ZvJsxsH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "b8cab7c6",
      "metadata": {
        "id": "b8cab7c6"
      },
      "source": [
        "#  Phase d'apprentissage"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8186c8ed",
      "metadata": {
        "id": "8186c8ed"
      },
      "source": [
        "## 1.1 création du RN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "Rijufc20s3Lb"
      },
      "id": "Rijufc20s3Lb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model(shape):\n",
        "    model=keras.models.Sequential()\n",
        "    model.add(keras.layers.Dense(units=shape/2, activation='relu', kernel_initializer='uniform', input_dim=shape))\n",
        "    model.add(keras.layers.Dense(units=1, activation='sigmoid', kernel_initializer='uniform'))\n",
        "    model.compile(optimizer='adam',\n",
        "                 loss='binary_crossentropy',\n",
        "                 metrics=['binary_accuracy'])\n",
        "    #model.add(keras.layers.Dense(64, activation='relu', name='HiddenLayer2'))\n",
        "    #model.add(keras.layers.Dense(32, activation='relu', name='HiddenLayer3'))                                                           \n",
        "    #model.add(keras.layers.Dense(1, name='OutputLayer'))\n",
        "    #model.compile(optimizer='adam',\n",
        "                 #loss='mse',\n",
        "                 #metrics=['mae','mse'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "rHHmBseLs5tB"
      },
      "id": "rHHmBseLs5tB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=get_model(shape)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "-NHpLpMas76H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "176ad796-223b-4fd3-d79d-b79e258af99b"
      },
      "id": "-NHpLpMas76H",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 3491)              24377653  \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 3492      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 24,381,145\n",
            "Trainable params: 24,381,145\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "626f276b",
      "metadata": {
        "id": "626f276b"
      },
      "source": [
        "## 1.2 entrainement"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit(X_train_vectors_tfidf.toarray(), y_train, batch_size=100, epochs=10, verbose=1, validation_data=(X_val_vectors_tfidf.toarray(), y_val))"
      ],
      "metadata": {
        "id": "5MmmfVnys-b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f89df7c4-60a8-4e7a-c1ef-d5b4644b4fad"
      },
      "id": "5MmmfVnys-b6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "52/52 [==============================] - 13s 231ms/step - loss: 0.3866 - binary_accuracy: 0.8637 - val_loss: 0.2204 - val_binary_accuracy: 0.9097\n",
            "Epoch 2/10\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0974 - binary_accuracy: 0.9690 - val_loss: 0.2229 - val_binary_accuracy: 0.9120\n",
            "Epoch 3/10\n",
            "52/52 [==============================] - 12s 227ms/step - loss: 0.0340 - binary_accuracy: 0.9934 - val_loss: 0.2184 - val_binary_accuracy: 0.9221\n",
            "Epoch 4/10\n",
            "52/52 [==============================] - 12s 222ms/step - loss: 0.0138 - binary_accuracy: 0.9982 - val_loss: 0.2357 - val_binary_accuracy: 0.9190\n",
            "Epoch 5/10\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0071 - binary_accuracy: 0.9996 - val_loss: 0.2492 - val_binary_accuracy: 0.9190\n",
            "Epoch 6/10\n",
            "52/52 [==============================] - 13s 252ms/step - loss: 0.0043 - binary_accuracy: 0.9998 - val_loss: 0.2661 - val_binary_accuracy: 0.9143\n",
            "Epoch 7/10\n",
            "52/52 [==============================] - 12s 231ms/step - loss: 0.0030 - binary_accuracy: 0.9998 - val_loss: 0.2723 - val_binary_accuracy: 0.9159\n",
            "Epoch 8/10\n",
            "52/52 [==============================] - 12s 231ms/step - loss: 0.0024 - binary_accuracy: 0.9998 - val_loss: 0.2833 - val_binary_accuracy: 0.9151\n",
            "Epoch 9/10\n",
            "52/52 [==============================] - 12s 228ms/step - loss: 0.0019 - binary_accuracy: 0.9998 - val_loss: 0.2953 - val_binary_accuracy: 0.9151\n",
            "Epoch 10/10\n",
            "52/52 [==============================] - 12s 228ms/step - loss: 0.0016 - binary_accuracy: 0.9998 - val_loss: 0.3015 - val_binary_accuracy: 0.9151\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02c45f21",
      "metadata": {
        "id": "02c45f21"
      },
      "source": [
        "## 1.3 evaluation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score=model.evaluate(X_val_vectors_tfidf.toarray(), y_val, verbose=1)\n",
        "print('x_test/loss       : {:5.4f}'.format(score[0]))\n",
        "print('x_test/accuracy   : {:5.4f}'.format(score[1]))"
      ],
      "metadata": {
        "id": "E4cUh5y3tCjp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cab0c6e1-89b0-4cc8-cd8c-bcb30ec5127c"
      },
      "id": "E4cUh5y3tCjp",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41/41 [==============================] - 2s 40ms/step - loss: 0.3015 - binary_accuracy: 0.9151\n",
            "x_test/loss       : 0.3015\n",
            "x_test/accuracy   : 0.9151\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_h=pd.DataFrame(data=history.history)\n",
        "df_h"
      ],
      "metadata": {
        "id": "j36wOoz_tFXL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "fa9dcc33-eada-4d54-962e-8337b14db7ea"
      },
      "id": "j36wOoz_tFXL",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c56598f9-1711-4f18-a661-7321e6c2a868\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>binary_accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_binary_accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.386632</td>\n",
              "      <td>0.863707</td>\n",
              "      <td>0.220382</td>\n",
              "      <td>0.909657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.097425</td>\n",
              "      <td>0.969042</td>\n",
              "      <td>0.222866</td>\n",
              "      <td>0.911994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.034044</td>\n",
              "      <td>0.993380</td>\n",
              "      <td>0.218409</td>\n",
              "      <td>0.922118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.013839</td>\n",
              "      <td>0.998248</td>\n",
              "      <td>0.235741</td>\n",
              "      <td>0.919003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.007081</td>\n",
              "      <td>0.999611</td>\n",
              "      <td>0.249195</td>\n",
              "      <td>0.919003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.004276</td>\n",
              "      <td>0.999805</td>\n",
              "      <td>0.266085</td>\n",
              "      <td>0.914330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.003021</td>\n",
              "      <td>0.999805</td>\n",
              "      <td>0.272269</td>\n",
              "      <td>0.915888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.002368</td>\n",
              "      <td>0.999805</td>\n",
              "      <td>0.283323</td>\n",
              "      <td>0.915109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.001903</td>\n",
              "      <td>0.999805</td>\n",
              "      <td>0.295294</td>\n",
              "      <td>0.915109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.001595</td>\n",
              "      <td>0.999805</td>\n",
              "      <td>0.301477</td>\n",
              "      <td>0.915109</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c56598f9-1711-4f18-a661-7321e6c2a868')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c56598f9-1711-4f18-a661-7321e6c2a868 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c56598f9-1711-4f18-a661-7321e6c2a868');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       loss  binary_accuracy  val_loss  val_binary_accuracy\n",
              "0  0.386632         0.863707  0.220382             0.909657\n",
              "1  0.097425         0.969042  0.222866             0.911994\n",
              "2  0.034044         0.993380  0.218409             0.922118\n",
              "3  0.013839         0.998248  0.235741             0.919003\n",
              "4  0.007081         0.999611  0.249195             0.919003\n",
              "5  0.004276         0.999805  0.266085             0.914330\n",
              "6  0.003021         0.999805  0.272269             0.915888\n",
              "7  0.002368         0.999805  0.283323             0.915109\n",
              "8  0.001903         0.999805  0.295294             0.915109\n",
              "9  0.001595         0.999805  0.301477             0.915109"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9155a2a3",
      "metadata": {
        "id": "9155a2a3"
      },
      "source": [
        "#  Phase de vérification"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction=model.predict(X_val_vectors_tfidf.toarray())"
      ],
      "metadata": {
        "id": "1i0L_Vd5tIAo"
      },
      "id": "1i0L_Vd5tIAo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"prediction: {prediction}\")\n",
        "print(f\"reality: {y_val}\")"
      ],
      "metadata": {
        "id": "fH57KqqatKlw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec017481-e901-4b01-ec71-4e79ebf78ee0"
      },
      "id": "fH57KqqatKlw",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prediction: [[8.5903002e-06]\n",
            " [1.5248388e-02]\n",
            " [1.8461943e-03]\n",
            " ...\n",
            " [9.9996895e-01]\n",
            " [9.9999845e-01]\n",
            " [9.9991536e-01]]\n",
            "reality: 4565    0\n",
            "356     1\n",
            "808     0\n",
            "6108    1\n",
            "4986    0\n",
            "       ..\n",
            "5765    1\n",
            "4841    1\n",
            "3802    1\n",
            "1715    1\n",
            "1       1\n",
            "Name: redif_label, Length: 1284, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_val=y_val.replace(1,'real')\n",
        "y_val=y_val.replace(0,'fake')\n",
        "y_val"
      ],
      "metadata": {
        "id": "MR1bC54dtP2K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5293303a-fdad-41e5-ac02-8d93d50e141d"
      },
      "id": "MR1bC54dtP2K",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4565    fake\n",
              "356     real\n",
              "808     fake\n",
              "6108    real\n",
              "4986    fake\n",
              "        ... \n",
              "5765    real\n",
              "4841    real\n",
              "3802    real\n",
              "1715    real\n",
              "1       real\n",
              "Name: redif_label, Length: 1284, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "redif_prediction=['test']*len(prediction)\n",
        "for i in range(len(prediction)):\n",
        "  if prediction[i]>=score[1]:\n",
        "    redif_prediction[i]='real'\n",
        "  else:\n",
        "    redif_prediction[i]='fake'\n",
        "print(f\"prediction: {redif_prediction}\")"
      ],
      "metadata": {
        "id": "hww2cWwEtSfs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8d3695d-8913-442c-800d-c9cbb92e5acd"
      },
      "id": "hww2cWwEtSfs",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prediction: ['fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real']\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}